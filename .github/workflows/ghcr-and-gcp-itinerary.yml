name: Docker push to GHCR, GCP Artifact Registry and deploy Cert Manager/Itinerary Service

on:
  push:
    branches: [ "main", "develop" ]
    tags: [ 'v*.*.*' ]
    paths:
      - 'services/itinerary-service/kubernetes/cert-manager-chart/Chart.yaml'
      - 'services/itinerary-service/kubernetes/itinerary-service-chart/Chart.yaml'
  workflow_dispatch:

jobs:
  check-versions:
    runs-on: ubuntu-latest
    outputs:
      cert_manager_changed: ${{ steps.detect.outputs.cert_manager_changed }}
      itinerary_service_changed: ${{ steps.detect.outputs.itinerary_service_changed }}
      itinerary_service_app_version: ${{ steps.detect.outputs.itinerary_service_app_version }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history to compare versions

      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version

      - name: Detect chart version changes
        id: detect
        run: |
          check_chart() {
            chart_dir=$1
            key_prefix=$2
          
            current=$(yq '.appVersion' "$chart_dir/Chart.yaml")
            previous=$(git show HEAD^:"$chart_dir/Chart.yaml" 2>/dev/null | yq '.appVersion' || echo "none")
          
            echo "${key_prefix}_app_version=$current" >> $GITHUB_OUTPUT
          
            if [ "$current" != "$previous" ]; then
              echo "Changes detected in appVersion for $chart_dir: $previous -> $current"
              echo "${key_prefix}_changed=true" >> $GITHUB_OUTPUT
            else
              echo "No changes in appVersion for $chart_dir"
              echo "${key_prefix}_changed=false" >> $GITHUB_OUTPUT
            fi
          }
          
          check_chart services/itinerary-service/kubernetes/cert-manager-chart cert_manager
          check_chart services/itinerary-service/kubernetes/itinerary-service-chart itinerary_service

  build-and-push:
    runs-on: ubuntu-latest
    needs: check-versions
    if: ${{ github.event.head_commit.message != 'skip-build' && needs.check-versions.outputs.itinerary_service_changed == 'true' }}
    environment: ${{ github.ref_name == 'main' && 'production' || 'develop' }}
    permissions:
      contents: read
      packages: write
      id-token: write  # needed for GCP Workload Identity

    outputs:
      backend_image: ${{ steps.export_image.outputs.backend_image }}
      app_version: ${{ steps.export_app_version.outputs.app_version }}

    steps:
      - uses: actions/checkout@v4

      # Login to GitHub Container Registry
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Login to Google Artifact Registry
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker for GCP
        run: gcloud auth configure-docker europe-west1-docker.pkg.dev

      # Build and push to both registries
      - name: Build and push to GHCR and GCP
        uses: docker/build-push-action@v6
        with:
          context: ./services/itinerary-service
          file: ./services/itinerary-service/Dockerfile
          push: true
          tags: |
            ghcr.io/${{ github.repository }}/${{ vars.PROJECT_ID }}:latest
            ghcr.io/${{ github.repository }}/${{ vars.PROJECT_ID }}:${{ needs.check-versions.outputs.itinerary_service_app_version }}
            europe-west1-docker.pkg.dev/${{ vars.PROJECT_ID }}/docker-repo/travel-backend:latest
            europe-west1-docker.pkg.dev/${{ vars.PROJECT_ID }}/docker-repo/travel-backend:${{ needs.check-versions.outputs.itinerary_service_app_version }}

      - name: Export image reference
        id: export_image
        run: echo "backend_image=europe-west1-docker.pkg.dev/${{ vars.PROJECT_ID }}/docker-repo/travel-backend:${{ needs.check-versions.outputs.itinerary_service_app_version }}" >> "$GITHUB_OUTPUT"

      - name: Export app version
        id: export_app_version
        run: echo "app_version=${{ needs.check-versions.outputs.itinerary_service_app_version }}" >> "$GITHUB_OUTPUT"

  deploy-cert-manager:
    runs-on: ubuntu-latest
    needs: check-versions
    if: ${{ needs.check-versions.outputs.cert_manager_changed == 'true' || github.event_name == 'workflow_dispatch' }}
    environment: ${{ github.ref_name == 'main' && 'production' || 'develop' }}
    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v4

      # Authenticate again for kubectl
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install GKE Auth Plugin
        run: |
          gcloud components install gke-gcloud-auth-plugin --quiet

      - name: Configure kubectl for GKE
        run: |
          gcloud container clusters get-credentials tripico-cluster --region europe-west1

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Create cert-manager DNS01 Service Account Secret
        env:
          CERT_MANAGER_SA_KEY: ${{ secrets.CERT_MANAGER_DNS01_SA_KEY_DEV }}
        run: |
          echo "Creating cert-manager DNS01 service account secret..."

          # Check if secret is set
          if [ -z "$CERT_MANAGER_SA_KEY" ]; then
            echo "❌ ERROR: CERT_MANAGER_DNS01_SA_KEY_DEV is not set!"
            echo "Please add the secret in GitHub: Settings → Secrets → Actions → Environment secrets (develop)"
            exit 1
          fi

          # Debug: Check secret length
          echo "✓ Secret is set (length: ${#CERT_MANAGER_SA_KEY} characters)"

          # Decode base64 secret and create JSON file
          echo "$CERT_MANAGER_SA_KEY" | base64 -d > /tmp/cert-manager-dns01-key.json || {
            echo "❌ ERROR: Failed to decode base64 secret!"
            echo "Secret might have invalid characters or wrong format"
            echo "First 50 chars of secret (for debugging): ${CERT_MANAGER_SA_KEY:0:50}..."
            exit 1
          }

          # Verify JSON is valid
          if ! jq empty /tmp/cert-manager-dns01-key.json 2>/dev/null; then
            echo "❌ ERROR: Decoded secret is not valid JSON!"
            exit 1
          fi

          echo "✓ Secret decoded successfully and is valid JSON"

          # Create namespace if not exists
          kubectl create namespace cert-manager --dry-run=client -o yaml | kubectl apply -f -

          # Create or update the secret
          kubectl create secret generic cert-manager-dns01-sa \
            --from-file=key.json=/tmp/cert-manager-dns01-key.json \
            --namespace=cert-manager \
            --dry-run=client -o yaml | kubectl apply -f -

          # Clean up temp file immediately
          rm -f /tmp/cert-manager-dns01-key.json

          echo " Secret created/updated successfully"

      - name: Verify secret was created
        run: |
          echo "Verifying secret exists..."
          kubectl get secret cert-manager-dns01-sa -n cert-manager
          echo " Secret verified"

      - name: Deploy cert-manager with DNS01
        working-directory: ./services/itinerary-service/kubernetes
        run: |
          helm repo add jetstack https://charts.jetstack.io
          helm repo update
          helm dependency update ./cert-manager-chart
          helm dependency build ./cert-manager-chart

          echo "Deploying cert-manager with values-dev.yaml"

          helm upgrade --install cert-manager ./cert-manager-chart \
            --namespace cert-manager \
            --create-namespace \
            -f ./cert-manager-chart/values-dev.yaml \
            --set cert-manager.installCRDs=true \
            --set cert-manager.global.rbac.create=true \
            --set cert-manager.serviceAccount.create=true \
            --set cert-manager.webhook.serviceAccount.create=true \
            --set cert-manager.cainjector.serviceAccount.create=true \
            --wait --timeout 5m

      - name: Wait for cert-manager to be ready
        run: |
          echo "Waiting for cert-manager pods to be ready..."
          kubectl wait --for=condition=Available --timeout=300s \
            deployment/cert-manager -n cert-manager
          kubectl wait --for=condition=Available --timeout=300s \
            deployment/cert-manager-webhook -n cert-manager
          kubectl wait --for=condition=Available --timeout=300s \
            deployment/cert-manager-cainjector -n cert-manager

          echo "All cert-manager deployments are ready!"
          kubectl get pods -n cert-manager


      - name: Verify ClusterIssuer
        run: |
          echo "Verifying ClusterIssuer..."

          # Wait a bit for ClusterIssuer to be created
          sleep 10

          kubectl get clusterissuer letsencrypt-prod -o yaml || echo "ClusterIssuer not ready yet"
          kubectl describe clusterissuer letsencrypt-prod

          # Check if ClusterIssuer is ready
          READY=$(kubectl get clusterissuer letsencrypt-prod -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' || echo "Unknown")
          if [ "$READY" = "True" ]; then
            echo " ClusterIssuer is ready!"
          else
            echo " ClusterIssuer not ready yet, status: $READY"
          fi

      - name: Verify Deployment
        run: |
          echo "=== Helm Release Status ==="
          helm status cert-manager --namespace cert-manager
          echo ""
          echo "=== Pod Status ==="
          kubectl get pods -n cert-manager -o wide
          echo ""
          echo "=== Service Status ==="
          kubectl get svc -n cert-manager
          echo ""
          echo "=== ClusterIssuer Status ==="
          kubectl get clusterissuer
          echo ""
          echo "=== Secret Status ==="
          kubectl get secret cert-manager-dns01-sa -n cert-manager -o jsonpath='{.metadata.creationTimestamp}'
          echo ""

  deploy-itinerary-service:
    runs-on: ubuntu-latest
    needs:
      - build-and-push
      - check-versions
    if: ${{ needs.check-versions.outputs.itinerary_service_changed == 'true' || github.event_name == 'workflow_dispatch' }}
    environment: ${{ github.ref_name == 'main' && 'production' || 'develop' }}
    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v4

      # Authenticate again for kubectl
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install GKE Auth Plugin
        run: |
          gcloud components install gke-gcloud-auth-plugin --quiet

      - name: Configure kubectl for GKE
        run: |
          gcloud container clusters get-credentials tripico-cluster --region europe-west1

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Install jq
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y jq

      - name: Install NGINX Ingress Controller (if not exists)
        run: |
          # Check if ingress-nginx namespace exists
          if ! kubectl get namespace ingress-nginx &>/dev/null; then
            echo "Installing NGINX Ingress Controller..."
            helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
            helm repo update
            helm install ingress-nginx ingress-nginx/ingress-nginx \
              --namespace ingress-nginx \
              --create-namespace \
              --wait --timeout 5m
          else
            echo "NGINX Ingress Controller already installed"
          fi

      # Cleanup Step - Uncomment if needed (if anything in the cluster is not managed by Helm and must be replaced)
      # - name: Clean up pre-existing resources (if not managed by Helm)
      #   run: |
      #     echo "Checking for non-Helm managed resources..."
      #           # Function to check and delete resource if not managed by Helm
      #     cleanup_resource() {
      #       local resource_type=$1
      #       local resource_name=$2
      #       if kubectl get $resource_type $resource_name &>/dev/null; then
      #         local managed_by=$(kubectl get $resource_type $resource_name -o jsonpath='{.metadata.labels.app\.kubernetes\.io/managed-by}' 2>/dev/null || echo "")
      #         if [ "$managed_by" != "Helm" ]; then
      #           echo "Found $resource_type/$resource_name not managed by Helm, deleting..."
      #           # Use --wait=false for PVC to avoid hanging, timeout for others
      #           if [ "$resource_type" == "pvc" ]; then
      #             kubectl delete $resource_type $resource_name --wait=false --timeout=30s 2>/dev/null || true
      #           else
      #             kubectl delete $resource_type $resource_name --timeout=30s 2>/dev/null || true
      #           fi
      #           echo "Deleted $resource_type/$resource_name"
      #         else
      #           echo "$resource_type/$resource_name is already managed by Helm"
      #         fi
      #       else
      #         echo "No pre-existing $resource_type/$resource_name found"
      #       fi
      #     }
      #     # Clean up all resources that might conflict
      #     # IMPORTANT: Delete in correct order to avoid hanging
      #     # 1. First delete ingress (no dependencies)
      #     cleanup_resource "ingress" "itinerary-ingress"
      #     # 2. Delete deployment
      #     cleanup_resource "deployment" "itinerary-service"
      #     # 3. Wait for pods to terminate (important!)
      #     echo "Waiting for pods to terminate..."
      #     kubectl wait --for=delete pod -l app=itinerary-service --timeout=60s 2>/dev/null || true
      #     # 4. Delete services
      #     cleanup_resource "service" "itinerary-service"
      #     # 5. Delete ServiceAccount (after pods are gone, before configmap)
      #     cleanup_resource "serviceaccount" "itinerary-service-sa"
      #     # 6. Delete configmap
      #     cleanup_resource "configmap" "app-config"
      #     # 7. Delete certificate resource (the Certificate CR, not cert-manager itself!)
      #     cleanup_resource "certificate" "itinerary-tls-cert"
      #     echo "Cleanup complete!"

      - name: Verify cert-manager is ready
        run: |
          echo "Checking cert-manager status..."
          kubectl wait --for=condition=ready pod -l app=cert-manager -n cert-manager --timeout=2m || true
          kubectl get pods -n cert-manager

      - name: Check for stuck Helm operations
        working-directory: ./services/itinerary-service/kubernetes
        run: |
          echo "Checking for stuck Helm operations..."
          RELEASE_STATUS=$(helm status itinerary-service -o json 2>/dev/null | jq -r '.info.status' || echo "not-found")
          
          echo "Current release status: $RELEASE_STATUS"
          
          if [ "$RELEASE_STATUS" == "pending-install" ] || [ "$RELEASE_STATUS" == "pending-upgrade" ] || [ "$RELEASE_STATUS" == "pending-rollback" ]; then
            echo "⚠️  Found stuck operation in status: $RELEASE_STATUS"
            echo "Rolling back to recover..."
            helm rollback itinerary-service 0 --wait --timeout 2m || {
              echo "Rollback failed or no history available"
              echo "Attempting to uninstall stuck release..."
              helm uninstall itinerary-service --wait --timeout 2m || echo "Uninstall also failed, will try fresh install"
            }
          elif [ "$RELEASE_STATUS" == "failed" ]; then
            echo "⚠️  Previous deployment failed, will retry with fresh deployment"
          elif [ "$RELEASE_STATUS" == "deployed" ]; then
            echo "✅ Current release is healthy"
          else
            echo "ℹ️  No existing release found"
          fi

      - name: Deploy with Helm
        working-directory: ./services/itinerary-service/kubernetes
        run: |
          # Check if release exists and is not in pending state
          if helm list | grep -q "^itinerary-service" && ! helm status itinerary-service -o json 2>/dev/null | jq -r '.info.status' | grep -q "pending"; then
            echo "Upgrading existing release..."
            helm upgrade itinerary-service ./itinerary-service-chart \
              -f ./itinerary-service-chart/${{ vars.VALUES_FILENAME }} \
              --set database.url="${{ vars.DB_URL }}" \
              --set database.password="${{ secrets.DB_PASSWORD }}" \
              --set itineraryService.image="${{ needs.build-and-push.outputs.backend_image }}" \
              --set gcp.projectId="${{ vars.PROJECT_ID }}" \
              --cleanup-on-fail \
              --rollback-on-failure \
              --wait --timeout 5m
          else
            echo "Installing new release..."
            helm install itinerary-service ./itinerary-service-chart \
              -f ./itinerary-service-chart/${{ vars.VALUES_FILENAME }} \
              --set database.url="${{ vars.DB_URL }}" \
              --set database.password="${{ secrets.DB_PASSWORD }}" \
              --set itineraryService.image="${{ needs.build-and-push.outputs.backend_image }}" \
              --set gcp.projectId="${{ vars.PROJECT_ID }}" \
              --create-namespace \
              --rollback-on-failure \
              --wait --timeout 5m
          fi

      - name: Verify Deployment
        run: |
          echo "=== Helm Release Status ==="
          helm status itinerary-service
          echo ""
          
          echo "=== Deployment Status ==="
          kubectl get deployment itinerary-service -o wide || echo "Deployment not found"
          echo ""
          
          echo "=== Pod Status ==="
          kubectl get pods -l app=itinerary-service -o wide
          echo ""
          
          echo "=== Pod Details (if any issues) ==="
          PODS=$(kubectl get pods -l app=itinerary-service -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$PODS" ]; then
            for pod in $PODS; do
              STATUS=$(kubectl get pod $pod -o jsonpath='{.status.phase}')
              echo "Pod: $pod - Status: $STATUS"
              if [ "$STATUS" != "Running" ]; then
                echo "Describing pod $pod:"
                kubectl describe pod $pod | tail -30
                echo ""
                echo "Recent logs from $pod:"
                kubectl logs $pod --tail=50 || echo "Could not get logs"
                echo ""
              fi
            done
          else
            echo "No pods found with label app=itinerary-service"
          fi
          
          echo "=== Service Status ==="
          kubectl get svc -l app.kubernetes.io/instance=itinerary-service
          echo ""
          
          echo "=== Ingress Status ==="
          kubectl get ingress
          echo ""
          
          echo "=== Certificate Status ==="
          kubectl get certificate itinerary-tls-cert -o wide || echo "Certificate not found"
          echo ""
          
          echo "=== Recent Events ==="
          kubectl get events --sort-by='.lastTimestamp' | grep itinerary | tail -20 || echo "No recent events"
